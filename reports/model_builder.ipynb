{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary statements\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from typing import List\n",
    "from scipy.stats import normaltest, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets data from SQl databases joining multiple tables allowing to set range of home price\n",
    "def pull_data(dbname = 'Seattle_housing', low_limit = '200000', high_limit = '2500000', year = 2018):\n",
    "    \"\"\"This function takes data from a postgreSQL database and returns a target dataframe and features dataframe.\"\"\"\n",
    "    engine = create_engine(f\"postgresql:///{dbname}\")\n",
    "    query = f\"\"\"SELECT \n",
    "               *\n",
    "            FROM rpsale rp\n",
    "            JOIN resbldg rd\n",
    "            ON CONCAT(rp.\"Major\", rp.\"Minor\") = Concat(rd.\"Major\", rd.\"Minor\")\n",
    "            JOIN parcel p\n",
    "            ON CONCAT(rp.\"Major\", rp.\"Minor\") = Concat(p.\"Major\", p.\"Minor\")\n",
    "            WHERE \"SalePrice\" > {low_limit} AND \"SalePrice\" < {high_limit}\n",
    "            AND SUBSTRING(\"DocumentDate\", 7, 4) = '{year}'\n",
    "         \"\"\"\n",
    "    seattle_housing = pd.read_sql(sql = query, con = engine)\n",
    "    return seattle_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds our base model in our case Square Feet of House, Water Front Location, and Presensce of a Porch\n",
    "def build_base(seattle_housing, target = 'SalePrice', basefeatures = [\"SqFtTotLiving\", \"WfntLocation\", \"SqFtOpenPorch\", \"SqFtEnclosedPorch\", \"TrafficNoise\", \"PowerLines\", \"OtherNuisances\"]):    \n",
    "    \"\"\"This function builds the DataFrames that will be used to make the base model from the housing database.\"\"\"\n",
    "    \n",
    "    dep_var = seattle_housing[[target]]\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    for feature in basefeatures:\n",
    "        features = pd.concat([features, seattle_housing[feature]], axis = 1)\n",
    "    if (\"SqFtOpenPorch\" in features.columns) and (\"SqFtEnclosedPorch\" in features.columns):\n",
    "        features['Porch'] = features['SqFtOpenPorch'] + features['SqFtEnclosedPorch']\n",
    "        for i, row in features.iterrows():\n",
    "            if row['Porch'] > 0:\n",
    "                row['Porch'] = 1\n",
    "            else:\n",
    "                row['Porch'] = 0\n",
    "        features = features.drop([\"SqFtOpenPorch\", \"SqFtEnclosedPorch\"], axis = 1)\n",
    "    else:\n",
    "        next\n",
    "    if \"WfntLocation\" in features.columns:\n",
    "        for i, row in features.iterrows():\n",
    "            if row['WfntLocation'] > 0:\n",
    "                row['WfntLocation'] = 1\n",
    "            else:\n",
    "                row['WfntLocation'] = 0\n",
    "    else:\n",
    "        next\n",
    "    \n",
    "    \n",
    "    def clean_noise(row: pd.DataFrame) -> int:\n",
    "        if (row['TrafficNoise'] > 0) or (row['PowerLines'] == 'Y') or (row['OtherNuisances'] == 'Y'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    features['Noise'] = features.apply(clean_noise, axis=1)\n",
    "    features = features.drop([\"TrafficNoise\", \"PowerLines\", \"OtherNuisances\"], axis = 1)\n",
    "    \n",
    "    return dep_var, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parses df for all continuos variables\n",
    "def load_con(input_df: pd.DataFrame, con_var: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Loads continuous variables\"\"\"\n",
    "    con_df = input_df[con_var]\n",
    "    return con_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parses df for cateborical variables\n",
    "def make_ohe(input_df: pd.DataFrame, cat_var: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"One Hot Encodes categorical variables\"\"\"\n",
    "    # Load necessary data\n",
    "    cat_df = input_df[cat_var]\n",
    "    # Create OHE object\n",
    "    ohe = OneHotEncoder(categories = 'auto', drop = 'first').fit(cat_df)\n",
    "    # Create OHE DataFrame\n",
    "    ohe_df = pd.DataFrame(ohe.transform(cat_df).toarray(), \n",
    "                          columns=ohe.get_feature_names(cat_var))\n",
    "    return ohe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines all dataframes together\n",
    "def combine(base: pd.DataFrame, cont: pd.DataFrame, cat: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Combines all three DataFrames\"\"\"\n",
    "    return pd.concat([base, cont, cat], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a linear regresion model with all values scaled\n",
    "def ols(dep_var, big_df):\n",
    "    ss = StandardScaler()\n",
    "    scaled_features = pd.DataFrame(ss.fit_transform(big_df), columns = big_df.columns)\n",
    "    model = sm.OLS(dep_var, sm.add_constant(scaled_features)).fit()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds values with high p-values and drop columns with too high corellation matrix\n",
    "def drop_features(model, big_df, p_val = 0.05, cor_val = 0.80):\n",
    "    lost_p = []\n",
    "    lost_cor = []\n",
    "    for i, p in enumerate(model.pvalues):\n",
    "        if p > p_val:\n",
    "            lost_p.append(model.params.index[i])\n",
    "            #big_df = big_df.drop(model.params.index[i], axis = 1)\n",
    "            \n",
    "    # Create correlation matrix\n",
    "    corr_matrix = big_df.corr().abs()\n",
    "\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "    # Find index of feature columns with correlation greater than 0.95\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > cor_val)]\n",
    "    # Drop features \n",
    "    big_df = big_df.drop(big_df[to_drop], axis=1)      \n",
    "            \n",
    "    edited_df = big_df\n",
    "    print(\"\"\"Features with p-values greater than 0.05: \n",
    "          \"\"\")\n",
    "    print(len(lost_p)) \n",
    "    \n",
    "    print(\"\"\"\n",
    "          \n",
    "    Lost Features from corellation: \"\"\")\n",
    "    print(len(to_drop))\n",
    "    \n",
    "    return edited_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of coefficients in order from greates to least\n",
    "def coef(model):\n",
    "    print(\"\"\"\n",
    "          \n",
    "          \"\"\")\n",
    "    #order = model.params.abs().sort_values(ascending = False)\n",
    "    order = model.params.sort_values(ascending = False)\n",
    "    \n",
    "    return order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds base model\n",
    "def base_model():\n",
    "    print(\"base model summary\")\n",
    "    seattle_housing = pull_data()\n",
    "    dep_var, features = build_base(seattle_housing)\n",
    "    base_model = ols(dep_var, features)\n",
    "    print(base_model.summary())\n",
    "    return base_model, dep_var, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(con_var: List[str], cat_var: List[str]) -> None:\n",
    "    \"\"\"makes model, gets report, display stats\"\"\"\n",
    "    # gets data from sql\n",
    "    seattle_housing = pull_data()\n",
    "    \n",
    "    #gets base data\n",
    "    dep_var, features = build_base(seattle_housing)\n",
    "    \n",
    "    # adds categorical and continuous variable\n",
    "    cont = load_con(seattle_housing, con_var)\n",
    "    cat = make_ohe(seattle_housing, cat_var)\n",
    "    big_df = combine(features, cont, cat)\n",
    "    \n",
    "    #prints updated summary\n",
    "    print(\"updated model summary\")\n",
    "    result = ols(dep_var, big_df)\n",
    "    edited_df = drop_features(result, big_df)\n",
    "    result_limited = ols(dep_var, edited_df)\n",
    "    \n",
    "    # shows variables with highest coefficients\n",
    "    print(\"variables with highest and lowest coefficients\")\n",
    "    print(coef(result_limited))\n",
    "    print (result_limited.summary())\n",
    "    return result_limited, dep_var, edited_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qqplot(model, save = False, filename = \"qq_plot.png\"):\n",
    "    \"\"\"Makes Q-Q Plot from statsmodel OLS model.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (5, 5), dpi = 150)\n",
    "    sm.qqplot(model.resid, ax = ax, line = 's')\n",
    "    ax.set_title('Q-Q Plot of Model')\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        fig.savefig(filename, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residplot(model, dep_var, save = False, filename = \"residual_plot.png\"):\n",
    "    \"\"\"Makes plot of residuals vs. expected values for a statsmodel OLS model.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (5,5), dpi = 150)\n",
    "    sns.residplot(dep_var, model.resid, ax = ax)\n",
    "    ax.set_title(f'Residual vs. Expected Value \\n Normalilty Test: {round(normaltest(model.resid)[0], 2)}, P-Value: {normaltest(model.resid)[1]}')\n",
    "    ax.set_xlabel('Expected Sale Price')\n",
    "    ax.set_ylabel('Residual of Sale Price')\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        fig.savefig(filename, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residdistplot(model, save = False, filename = \"residual_dist.png\"):\n",
    "    \"\"\"Makes a distribution plot of residuals from statsmodel OLS model.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (7,5), dpi = 150)\n",
    "    sns.distplot(model.resid, ax = ax)\n",
    "    ax.set_title(f'Distribution of Residuals \\n Normalilty Test: {round(normaltest(model.resid)[0], 2)}, P-Value: {normaltest(model.resid)[1]}')\n",
    "    ax.set_xlabel('Residual of Sale Price')\n",
    "    ax.set_ylabel('Frequency of Residual')\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        fig.savefig(filename, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrmatrixplot(features, save = False, filename = \"correlation_matrix.png\"):\n",
    "    \"\"\"Makes a correlation matrix heatmap from a pandas DataFrame of features.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize = (5, 5), dpi = 150)\n",
    "    corr = features.corr()\n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(corr, ax = ax, cbar = True, xticklabels= False, cmap = 'Blues', yticklabels= False, square = True, mask = mask)\n",
    "    ax.set_facecolor(color='white')\n",
    "    ax.set_title('Features Correlation Matrix')\n",
    "    fig.tight_layout()\n",
    "    if save == True:\n",
    "        fig.savefig(filename, dpi = 300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:linreg-env]",
   "language": "python",
   "name": "conda-env-linreg-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
